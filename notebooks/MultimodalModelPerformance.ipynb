{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Multimodal Transformers for Visual Question Answering \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we note the best performances of the various Multimodal Transformer Fusion Models for Visual Question Answering on the DAQUAR Dataset for comparison.\n",
    "\n",
    "Training has been done with the following hyperparameters for all the models:\n",
    "\n",
    "| Hyperparameter | Value |\n",
    "| :---: | :---: |\n",
    "| No. of Epochs | 5 |\n",
    "| Batch Size | 32 |\n",
    "| Learning Rate | 5e-5 |\n",
    "| Optimizer | AdamW (with default settings) |\n",
    "| Use fp16 16-bit (mixed) precision | True |\n",
    "| Intermediate Dimensions (for Fusion Layer) | 512 |\n",
    "| Seed | 12345 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Text Transformer | Image Transformer | Wu & Palmer Score | Accuracy | F1 | No. of Trainable Parameters |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| BERT | ViT | 0.286 | 0.235 | 0.020 | 197M |\n",
    "| BERT | DeiT | 0.297 | 0.246 | 0.027 | 197M |\n",
    "| BERT | BEiT | 0.303 | 0.254 | **0.034** | 196M |\n",
    "| RoBERTa | ViT | 0.294 | 0.246 | 0.025 | 212M |\n",
    "| RoBERTa | DeiT | 0.291 | 0.242 | 0.028 | 212M |\n",
    "| RoBERTa | BEiT | _**0.308**_ | _**0.261**_ | 0.033 | 211M |\n",
    "| ALBERT | ViT | 0.265 | 0.215 | 0.018 | 99M |\n",
    "| ALBERT | DeiT | 0.140 | 0.085 | 0.002 | 99M |\n",
    "| ALBERT | BEiT | 0.220 | 0.162 | 0.017 | 98M |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Legend:**\n",
    "- BERT (Bidirectional Encoder Representations from Transformers): `'bert-base-uncased'`\n",
    "- RoBERTa (Robustly Optimized BERT Pretraining Approach): `'roberta-base'`\n",
    "- ALBERT (A Lite BERT): `'albert-base-v2'`\n",
    "- ViT (Vision Transformer): `'google/vit-base-patch16-224-in21k'`\n",
    "- DeiT (Data-Efficient Image Transformer): `'facebook/deit-base-distilled-patch16-224'`\n",
    "- BEiT (Bidirectional Encoder representation from Image Transformers): `'microsoft/beit-base-patch16-224-pt22k-ft22k'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
